{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "from holidays import Germany\n",
    "from multiprocessing import cpu_count\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, GroupNormalizer\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'batch_size_high_tft'\n",
    "seed_everything(69, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train data\n",
    "train = pd.read_csv('../../Data/Raw/train/raw.csv')\n",
    "train['Date'] = pd.to_datetime(train['Date'], dayfirst=True)\n",
    "train = train[(train['Date'].dt.year >= 2018) & (train['Date'].dt.year <= 2022)]\n",
    "\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test data\n",
    "test = pd.read_csv('../../Data/Raw/test/raw.csv')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "def data_preparation(data, test=False, train_min_timestamp=0):\n",
    "    # Melting variable columns\n",
    "    data = pd.melt(data, id_vars=['Datetime', 'Date', 'Time'], value_vars=['50Hertz', 'Amprion', 'TenneT', 'TransnetBW', 'Total', 'Delta'], var_name='control_area', value_name='power_consumption')\n",
    "\n",
    "    # Convert 'Datetime' column to datetime objects\n",
    "    data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "    # Numericals\n",
    "    # Calculate Unix timestamp\n",
    "    data['unix_timestamp'] = data['Datetime'].apply(lambda x: int(x.timestamp()))\n",
    "\n",
    "    # Setting the start index\n",
    "    if test==False:\n",
    "        min_timestamp = data['unix_timestamp'].min()\n",
    "    elif test==True:\n",
    "        min_timestamp = train_min_timestamp\n",
    "\n",
    "    # Calculate passed time intervals\n",
    "    data['quarter_hours_from_start'] = (data['unix_timestamp'] - min_timestamp) // 900\n",
    "    data['hours_from_start'] = (data['unix_timestamp'] - min_timestamp) // 3600\n",
    "    data['days_from_start'] = (data['unix_timestamp'] - min_timestamp) // 86400\n",
    "    data['weeks_from_start'] = (data['unix_timestamp'] - min_timestamp) // 604800\n",
    "    data['months_from_start'] = (data['unix_timestamp'] - min_timestamp) // 2629743\n",
    "    data['years_from_start'] = (data['unix_timestamp'] - min_timestamp) // 31556926\n",
    "\n",
    "    # Extract date components\n",
    "    data['hour_of_day'] = data['Datetime'].dt.hour\n",
    "    data['minute_of_hour'] = data['Datetime'].dt.minute\n",
    "    data['day_of_week'] = data['Datetime'].dt.dayofweek\n",
    "    data['day_of_year'] = data['Datetime'].dt.dayofyear\n",
    "    data['month_of_year'] = data['Datetime'].dt.month\n",
    "    data['year'] = data['Datetime'].dt.year\n",
    "    data['quarter'] = data['Datetime'].dt.quarter\n",
    "\n",
    "    #Categricals\n",
    "    # Check if it's a weekend or holiday\n",
    "    holidays = Germany(years=range(2015, 2024), language='en_US')\n",
    "    data['is_weekend'] = (data['Datetime'].dt.dayofweek >= 5).astype(str)\n",
    "    data['is_holiday'] = data['Date'].apply(lambda x: str(x in holidays))\n",
    "\n",
    "    # Add name of holiday if is_holiday is 1\n",
    "    data['holiday_name'] = data.apply(lambda row: holidays.get(row['Date']) if row['is_holiday'] == 'True' else 'None', axis=1)\n",
    "\n",
    "    # Add name of weekday\n",
    "    data['weekday_name'] = data['Datetime'].dt.day_name()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming train data\n",
    "train = data_preparation(train)\n",
    "train.to_csv('../../Data/processed/train/tft_input.csv', index=False)\n",
    "\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming test data\n",
    "test = data_preparation(test, test=True, train_min_timestamp=1420070400)\n",
    "test.to_csv('../../Data/processed/test/tft_input.csv', index=False)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "# Preparing dataloader\n",
    "max_prediction_length = 4*24*7 # a week in quarterhours\n",
    "max_encoder_length = 4*24*7\n",
    "training_cutoff = train['quarter_hours_from_start'].max() - max_prediction_length\n",
    "\n",
    "#TSDS pytorch forecasting with given arguments\n",
    "training_set = TimeSeriesDataSet(\n",
    "    data=train[lambda x: x.quarter_hours_from_start <= training_cutoff],\n",
    "    time_idx='quarter_hours_from_start',\n",
    "    target='power_consumption',\n",
    "    group_ids=['control_area'],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_encoder_length=4*24,\n",
    "    min_prediction_length=4*24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=['control_area'],\n",
    "    time_varying_known_categoricals=['is_weekend', 'is_holiday', 'holiday_name', 'weekday_name'],\n",
    "    time_varying_known_reals=['unix_timestamp', 'quarter_hours_from_start', 'hours_from_start', \n",
    "                              'days_from_start', 'weeks_from_start', 'months_from_start', \n",
    "                              'years_from_start', 'hour_of_day', 'minute_of_hour', \n",
    "                              'day_of_week', 'day_of_year', 'month_of_year', \n",
    "                              'year', 'quarter'],\n",
    "    time_varying_unknown_reals=['power_consumption'],\n",
    "    allow_missing_timesteps=True,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    target_normalizer=GroupNormalizer(groups=['control_area'], transformation='softplus'))\n",
    "\n",
    "#Split validation set\n",
    "validation_set = TimeSeriesDataSet.from_dataset(training_set, train, predict=True, stop_randomization=True)\n",
    "\n",
    "# Batch size\n",
    "batch_size = 128 ## observed\n",
    "\n",
    "#Build dataloader\n",
    "workers = cpu_count()\n",
    "train_dataloader = training_set.to_dataloader(train=True, batch_size=batch_size, num_workers=workers)\n",
    "val_dataloader = validation_set.to_dataloader(train=False, batch_size=batch_size, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition  \n",
    "\n",
    "# Actual model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training_set,\n",
    "    hidden_size=8,\n",
    "    lstm_layers=2,\n",
    "    dropout=0.5, ## observed\n",
    "    output_size=7,\n",
    "    loss=QuantileLoss(),\n",
    "    attention_head_size=4,\n",
    "    learning_rate=1e-3, ## observed\n",
    "    log_interval=4*24,\n",
    "    log_val_interval=4*24,\n",
    "    log_gradient_flow=False,\n",
    "    reduce_on_plateau_patience=1000,\n",
    "    logging_metrics=None)\n",
    "\n",
    "# Outside features\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', \n",
    "                        min_delta=0.1,\n",
    "                        patience=3,\n",
    "                        verbose=True, \n",
    "                        mode='min')\n",
    "lr_logger = LearningRateMonitor()  \n",
    "logger = TensorBoardLogger(f'tensorboard/{model_name}')\n",
    "\n",
    "# Trainer instance\n",
    "trainer = Trainer(\n",
    "    max_epochs=15,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.5, ## observed\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the time of model training\n",
    "def measure_training_time(start_time):\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    hours, remainder = divmod(execution_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    time_str = f\"The model training took {int(hours)} hours, {int(minutes)} minutes und {int(seconds)} seconds.\"\n",
    "    with open(f'{model_name}_training_time.txt', \"w\") as file:\n",
    "        file.write(time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "start_time = time.time()\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader)\n",
    "\n",
    "measure_training_time(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading best model\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "shutil.copy(best_model_path, f'{model_name}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing best model\n",
    "tft = TemporalFusionTransformer.load_from_checkpoint(f'{model_name}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_actuals(start_date, end_date):\n",
    "    predicted_length = int((end_date - start_date).total_seconds() / (15 * 60))\n",
    "\n",
    "    timestamp_end = start_date.timestamp()\n",
    "\n",
    "    timestamp_start = timestamp_end - ((15 * 60) * (4*24*8))\n",
    "\n",
    "    if predicted_length <= 4*24*7:\n",
    "        test_range = test[(test['unix_timestamp'] >= timestamp_start) & (test['unix_timestamp'] <= timestamp_end)].reset_index(drop=True)\n",
    "\n",
    "        prediction_array = tft.predict(test_range, return_index=True)\n",
    "\n",
    "        control_areas = prediction_array[1]['control_area'].to_list()\n",
    "\n",
    "        pred_df = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(control_areas)):\n",
    "            pred_df[control_areas[i]] = prediction_array[0].numpy().tolist()[i][:predicted_length]\n",
    "    else:\n",
    "        pred_df = pd.DataFrame()\n",
    "        remaining_steps = predicted_length\n",
    "        while remaining_steps > 0:\n",
    "            current_prediction_length = min(remaining_steps, 4*24*7)\n",
    "            \n",
    "            # Predict the next interval\n",
    "            test_range = test[(test['unix_timestamp'] >= timestamp_start) & (test['unix_timestamp'] <= timestamp_end)].reset_index(drop=True)\n",
    "            prediction_array = tft.predict(test_range, return_index=True)\n",
    "            control_areas = prediction_array[1]['control_area'].to_list()\n",
    "\n",
    "            # Accumulate predictions for the current interval\n",
    "            temp_df = pd.DataFrame()\n",
    "            for i in range(len(control_areas)):\n",
    "                temp_df[control_areas[i]] = prediction_array[0].numpy().tolist()[i]\n",
    "            \n",
    "            pred_df = pd.concat([pred_df, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "            # Update time range\n",
    "            timestamp_end += current_prediction_length * (15*60)\n",
    "            timestamp_start = timestamp_end - (900 * (4*24*8))\n",
    "\n",
    "            # Update remaining steps\n",
    "            remaining_steps -= current_prediction_length\n",
    "\n",
    "    test_data_start = start_date.timestamp() - (15*60)\n",
    "    test_data_end = test_data_start + (predicted_length * (15*60))\n",
    "\n",
    "    test_data = test[(test['unix_timestamp'] > test_data_start) & (test['unix_timestamp'] <= test_data_end)]\n",
    "\n",
    "    test_df = test_data.pivot(index=[x for x in list(test_data.columns) if x not in ['control_area', 'power_consumption']], \n",
    "            columns='control_area', \n",
    "            values='power_consumption').reset_index()\n",
    "    \n",
    "    pred_df = pred_df[['50Hertz', 'Amprion', 'TenneT', 'TransnetBW', 'Total', 'Delta']]\n",
    "\n",
    "    if len(pred_df) != len(test_df):\n",
    "        if len(pred_df) < len(test_df):\n",
    "            test_df = test_df[:len(pred_df)]\n",
    "        elif len(test_df) < len(pred_df):\n",
    "            pred_df = pred_df[:len(test_df)]\n",
    "\n",
    "    return pred_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance calculation\n",
    "def performance_check(y, y_hat):\n",
    "    raw_mape = mean_absolute_percentage_error(y, y_hat)\n",
    "    raw_sdmae = mean_absolute_error(y, y_hat) / np.std(y)\n",
    "    return raw_mape, raw_sdmae\n",
    "\n",
    "# Perfromance evaluation\n",
    "def performance_evaluation(n_iter, n_days):\n",
    "    metrics = []\n",
    "    start_date = datetime(2023, 1, 31)\n",
    "    end_date = datetime(2023, 7, 31)\n",
    "    date_range = (end_date - start_date).days - n_days\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        random_days_offset = random.randint(0, date_range)\n",
    "        random_start_date = start_date + timedelta(days=random_days_offset)\n",
    "        random_end_date = random_start_date + timedelta(days=n_days)\n",
    "\n",
    "        pred_df, test_df = get_predictions_and_actuals(random_start_date, random_end_date)\n",
    "\n",
    "        for n in pred_df.columns:\n",
    "            mape, sdmae = performance_check(test_df[n], pred_df[n])\n",
    "            metrics.append((n, mape, sdmae))\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics, columns=['control_area', 'mape', 'sdmae'])\n",
    "    grouped_df = metrics_df.groupby('control_area').agg({'mape': 'mean', 'sdmae': 'mean'}).reset_index()\n",
    "    output_df = grouped_df.rename(columns={'mape': 'avg_mape', 'sdmae': 'avg_sdmae'})\n",
    "        \n",
    "    return output_df\n",
    "\n",
    "# Metric formatting for plotting\n",
    "def metric_formatting(raw_mape, raw_sdmae):\n",
    "    if raw_mape < 10:\n",
    "        mape = f'{round(raw_mape*100, 2)}%'\n",
    "    else:\n",
    "        mape = 'too high'\n",
    "    if raw_sdmae < 10:\n",
    "        sdmae = round(raw_sdmae, 4)\n",
    "    else:\n",
    "        sdmae = 'too high'\n",
    "    return mape, sdmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting predictions against test data\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# Set test interval\n",
    "start_date = pd.to_datetime('01.02.2023', dayfirst=True)\n",
    "end_date = pd.to_datetime('02.02.2023', dayfirst=True)\n",
    "\n",
    "# Get predictions and actuals\n",
    "pred_df, test_df= get_predictions_and_actuals(start_date, end_date)\n",
    "\n",
    "fig.suptitle('TFT day prediction', fontsize=16, y=0.94)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        control_area = list(pred_df.columns)[i * 2 + j]\n",
    "\n",
    "        pred_data = pred_df[control_area]\n",
    "        actual_data = test_df[control_area]\n",
    "\n",
    "        metric_df = performance_evaluation(100, 1)\n",
    "        mape, sdmae = metric_formatting(metric_df.loc[metric_df['control_area'] == control_area, 'avg_mape'].values[0],\n",
    "                                        metric_df.loc[metric_df['control_area'] == control_area, 'avg_sdmae'].values[0])\n",
    "\n",
    "        ax[i][j].plot(actual_data.reset_index(drop=True), label='Actual')\n",
    "        ax[i][j].plot(pred_data.reset_index(drop=True), label='Prediction')\n",
    "        ax[i][j].set_title(control_area)\n",
    "        ax[i][j].set_title(f'{control_area} | AVG MAPE: {mape} | AVG SDMAE: {sdmae}', loc=\"center\", pad=10)\n",
    "        ax[i][j].legend()\n",
    "\n",
    "plt.savefig(f'{model_name}_day_prediction.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting predictions against test data\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# Set test interval\n",
    "start_date = pd.to_datetime('12.04.2023', dayfirst=True)\n",
    "end_date = pd.to_datetime('20.04.2023', dayfirst=True)\n",
    "\n",
    "# Get predictions and actuals\n",
    "pred_df, test_df= get_predictions_and_actuals(start_date, end_date)\n",
    "\n",
    "fig.suptitle('TFT week prediction', fontsize=16, y=0.94)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        control_area = list(pred_df.columns)[i * 2 + j]\n",
    "\n",
    "        pred_data = pred_df[control_area]\n",
    "        actual_data = test_df[control_area]\n",
    "\n",
    "        metric_df = performance_evaluation(100, 7)\n",
    "        mape, sdmae = metric_formatting(metric_df.loc[metric_df['control_area'] == control_area, 'avg_mape'].values[0],\n",
    "                                        metric_df.loc[metric_df['control_area'] == control_area, 'avg_sdmae'].values[0])\n",
    "\n",
    "        ax[i][j].plot(actual_data.reset_index(drop=True), label='Actual')\n",
    "        ax[i][j].plot(pred_data.reset_index(drop=True), label='Prediction')\n",
    "        ax[i][j].set_title(control_area)\n",
    "        ax[i][j].set_title(f'{control_area} | AVG MAPE: {mape} | AVG SDMAE: {sdmae}', loc=\"center\", pad=10)\n",
    "        ax[i][j].legend()\n",
    "\n",
    "plt.savefig(f'{model_name}_week_prediction.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting predictions against test data\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# Set test interval\n",
    "start_date = pd.to_datetime('21.06.2023', dayfirst=True)\n",
    "end_date = pd.to_datetime('21.07.2023', dayfirst=True)\n",
    "\n",
    "# Get predictions and actuals\n",
    "pred_df, test_df= get_predictions_and_actuals(start_date, end_date)\n",
    "\n",
    "fig.suptitle('TFT month prediction', fontsize=16, y=0.94)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        control_area = list(pred_df.columns)[i * 2 + j]\n",
    "\n",
    "        pred_data = pred_df[control_area]\n",
    "        actual_data = test_df[control_area]\n",
    "\n",
    "        metric_df = performance_evaluation(100, 30)\n",
    "        mape, sdmae = metric_formatting(metric_df.loc[metric_df['control_area'] == control_area, 'avg_mape'].values[0],\n",
    "                                        metric_df.loc[metric_df['control_area'] == control_area, 'avg_sdmae'].values[0])\n",
    "\n",
    "        ax[i][j].plot(actual_data.reset_index(drop=True), label='Actual')\n",
    "        ax[i][j].plot(pred_data.reset_index(drop=True), label='Prediction')\n",
    "        ax[i][j].set_title(control_area)\n",
    "        ax[i][j].set_title(f'{control_area} | AVG MAPE: {mape} | AVG SDMAE: {sdmae}', loc=\"center\", pad=10)\n",
    "        ax[i][j].legend()\n",
    "\n",
    "plt.savefig(f'{model_name}_month_prediction.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting predictions against test data\n",
    "fig, ax = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# Set test interval\n",
    "start_date = pd.to_datetime('31.01.2023', dayfirst=True)\n",
    "end_date = pd.to_datetime('31.07.2023', dayfirst=True)\n",
    "\n",
    "# Get predictions and actuals\n",
    "pred_df, test_df= get_predictions_and_actuals(start_date, end_date)\n",
    "\n",
    "fig.suptitle('TFT complete test-dataset prediction', fontsize=16, y=0.94)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        control_area = list(pred_df.columns)[i * 2 + j]\n",
    "\n",
    "        pred_data = pred_df[control_area]\n",
    "        actual_data = test_df[control_area]\n",
    "\n",
    "        mape, sdmae = metric_formatting(*performance_check(pred_data, actual_data))\n",
    "\n",
    "        ax[i][j].plot(actual_data.reset_index(drop=True), label='Actual')\n",
    "        ax[i][j].plot(pred_data.reset_index(drop=True), label='Prediction')\n",
    "        ax[i][j].set_title(control_area)\n",
    "        ax[i][j].set_title(f'{control_area} | AVG MAPE: {mape} | AVG SDMAE: {sdmae}', loc=\"center\", pad=10)\n",
    "        ax[i][j].legend()\n",
    "\n",
    "plt.savefig(f'{model_name}_complete_prediction.svg', format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
